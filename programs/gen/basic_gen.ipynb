{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('aug_nine_var.xlsx').iloc[:,1::]\n",
    "X = df.iloc[:,0:21]\n",
    "y = df.iloc[:,21::].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 21)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = tf.keras.models.load_model('dnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(real, X_pred):\n",
    "    return dnn_model(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_latest():\n",
    "    df = pd.read_excel('aug_nine_var.xlsx').iloc[:,1::]\n",
    "    X = df.iloc[:,0:21]\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    return X[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.Sequential()\n",
    "generator.add(tf.keras.layers.Dense(128, input_dim=21, activation='relu'))\n",
    "generator.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "generator.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "generator.add(tf.keras.layers.Dense(21, activation='tanh'))\n",
    "\n",
    "generator.compile(loss=my_loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: [[39.971718]]\n",
      "epoch: 10, loss: [[38.992382]]\n",
      "epoch: 20, loss: [[36.646557]]\n",
      "epoch: 30, loss: [[32.12387]]\n",
      "epoch: 40, loss: [[28.517868]]\n",
      "epoch: 50, loss: [[27.388714]]\n",
      "epoch: 60, loss: [[25.797562]]\n",
      "epoch: 70, loss: [[25.63386]]\n",
      "epoch: 80, loss: [[24.803062]]\n",
      "epoch: 90, loss: [[24.497356]]\n",
      "epoch: 100, loss: [[24.563301]]\n",
      "epoch: 110, loss: [[24.27842]]\n",
      "epoch: 120, loss: [[24.216526]]\n",
      "epoch: 130, loss: [[24.281258]]\n",
      "epoch: 140, loss: [[24.206425]]\n",
      "epoch: 150, loss: [[24.031727]]\n",
      "epoch: 160, loss: [[24.32211]]\n",
      "epoch: 170, loss: [[24.036713]]\n",
      "epoch: 180, loss: [[24.068684]]\n",
      "epoch: 190, loss: [[24.229069]]\n",
      "epoch: 200, loss: [[24.202553]]\n",
      "epoch: 210, loss: [[24.005543]]\n",
      "epoch: 220, loss: [[24.160519]]\n",
      "epoch: 230, loss: [[24.125542]]\n",
      "epoch: 240, loss: [[24.173851]]\n",
      "epoch: 250, loss: [[24.17445]]\n",
      "epoch: 260, loss: [[24.05065]]\n",
      "epoch: 270, loss: [[24.019905]]\n",
      "epoch: 280, loss: [[23.98544]]\n",
      "epoch: 290, loss: [[24.132898]]\n",
      "epoch: 300, loss: [[23.993885]]\n",
      "epoch: 310, loss: [[23.921478]]\n",
      "epoch: 320, loss: [[23.963856]]\n",
      "epoch: 330, loss: [[23.964136]]\n",
      "epoch: 340, loss: [[23.965427]]\n",
      "epoch: 350, loss: [[23.898088]]\n",
      "epoch: 360, loss: [[23.892445]]\n",
      "epoch: 370, loss: [[23.95403]]\n",
      "epoch: 380, loss: [[23.978119]]\n",
      "epoch: 390, loss: [[24.078249]]\n",
      "epoch: 400, loss: [[23.970375]]\n",
      "epoch: 410, loss: [[23.91954]]\n",
      "epoch: 420, loss: [[23.947458]]\n",
      "epoch: 430, loss: [[23.947039]]\n",
      "epoch: 440, loss: [[23.914043]]\n",
      "epoch: 450, loss: [[23.92138]]\n",
      "epoch: 460, loss: [[23.88832]]\n",
      "epoch: 470, loss: [[23.922602]]\n",
      "epoch: 480, loss: [[23.929895]]\n",
      "epoch: 490, loss: [[23.983177]]\n",
      "epoch: 500, loss: [[23.923973]]\n",
      "epoch: 510, loss: [[23.914074]]\n",
      "epoch: 520, loss: [[23.925617]]\n",
      "epoch: 530, loss: [[23.88824]]\n",
      "epoch: 540, loss: [[23.935116]]\n",
      "epoch: 550, loss: [[23.96296]]\n",
      "epoch: 560, loss: [[23.9607]]\n",
      "epoch: 570, loss: [[23.880356]]\n",
      "epoch: 580, loss: [[23.875652]]\n",
      "epoch: 590, loss: [[23.912956]]\n",
      "epoch: 600, loss: [[23.86204]]\n",
      "epoch: 610, loss: [[23.881535]]\n",
      "epoch: 620, loss: [[24.04679]]\n",
      "epoch: 630, loss: [[23.920002]]\n",
      "epoch: 640, loss: [[23.906183]]\n",
      "epoch: 650, loss: [[23.964355]]\n",
      "epoch: 660, loss: [[23.854599]]\n",
      "epoch: 670, loss: [[23.860086]]\n",
      "epoch: 680, loss: [[23.889992]]\n",
      "epoch: 690, loss: [[23.93889]]\n",
      "epoch: 700, loss: [[23.935667]]\n",
      "epoch: 710, loss: [[24.041424]]\n",
      "epoch: 720, loss: [[23.989628]]\n",
      "epoch: 730, loss: [[23.871613]]\n",
      "epoch: 740, loss: [[23.864117]]\n",
      "epoch: 750, loss: [[24.060684]]\n",
      "epoch: 760, loss: [[23.898119]]\n",
      "epoch: 770, loss: [[23.94164]]\n",
      "epoch: 780, loss: [[24.01081]]\n",
      "epoch: 790, loss: [[23.885422]]\n",
      "epoch: 800, loss: [[23.957954]]\n",
      "epoch: 810, loss: [[23.943718]]\n",
      "epoch: 820, loss: [[23.884077]]\n",
      "epoch: 830, loss: [[23.97492]]\n",
      "epoch: 840, loss: [[23.865358]]\n",
      "epoch: 850, loss: [[23.920284]]\n",
      "epoch: 860, loss: [[23.908314]]\n",
      "epoch: 870, loss: [[23.853909]]\n",
      "epoch: 880, loss: [[23.849367]]\n",
      "epoch: 890, loss: [[23.887108]]\n",
      "epoch: 900, loss: [[23.896914]]\n",
      "epoch: 910, loss: [[23.990307]]\n",
      "epoch: 920, loss: [[23.916183]]\n",
      "epoch: 930, loss: [[23.943243]]\n",
      "epoch: 940, loss: [[23.872698]]\n",
      "epoch: 950, loss: [[23.851788]]\n",
      "epoch: 960, loss: [[23.868315]]\n",
      "epoch: 970, loss: [[23.919878]]\n",
      "epoch: 980, loss: [[23.950634]]\n",
      "epoch: 990, loss: [[23.986835]]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "pop_result = []\n",
    "for i in range(1000):\n",
    "    noise = tf.random.normal([1, 21])\n",
    "    X_pred = generator.predict(noise, verbose=0)\n",
    "    loss = my_loss(noise, X_pred)\n",
    "\n",
    "    pop = dnn_model.predict(X_pred, verbose=0)\n",
    "    generator.train_on_batch(noise, X_pred)\n",
    "    \n",
    "    result.append(X_pred)\n",
    "    pop_result.append(pop)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"epoch: {i}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(result).reshape(1000, 21)\n",
    "pop_result = np.array(pop_result).reshape(1000, 1)\n",
    "X_result = scaler.inverse_transform(result)\n",
    "\n",
    "pd_result = pd.DataFrame(X_result)\n",
    "pd_result.to_excel('basic.xlsx')\n",
    "\n",
    "pd_pop_result = pd.DataFrame(pop_result)\n",
    "pd_pop_result.to_excel('basic_pop.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tens-cpu38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d69d666dea1d14e04e4d38b06e20d4d04fc31a418cef854ebdceb8b68a0927a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
