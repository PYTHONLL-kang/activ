{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand\n",
    "import math\n",
    "\n",
    "from collections import deque\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = pd.read_excel('./documents/nov_nine_var.xlsx').to_numpy()\n",
    "goal_data = pd.read_excel('./documents/result/basic_formula.xlsx').to_numpy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(real_data[:,1:22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax(l):\n",
    "    return max(range(len(l)), key=lambda i: l[i])\n",
    "\n",
    "def argmin(l):\n",
    "    return min(range(len(l)), key=lambda i: l[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.508362 0.497095 0.497007 0.494148 0.502046 0.500935 0.502494 0.500844\n",
      " 0.504019 0.502051 0.494209 0.498915 0.504325 0.500418 0.500487 0.49806\n",
      " 0.492942 0.494332 0.511553 0.498666 0.497106]\n",
      "[0.       0.981228 0.       1.       0.992791 0.996215 0.002543 0.777164\n",
      " 0.091221 0.463374 0.4      0.575188 0.267857 0.320856 0.231343 0.228723\n",
      " 1.       0.030248 0.496376 0.430401 1.      ]\n"
     ]
    }
   ],
   "source": [
    "start = scaler.transform(real_data[:,1:22])[-1].reshape(1, 21)\n",
    "goal = scaler.transform(goal_data[:,1:22])[argmin(goal_data[:,-1])].reshape(1, 21)\n",
    "\n",
    "print(goal[0])\n",
    "print(start[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_state = scaler.transform(real_data[:,1:22])[-13:-1].reshape(1, 12, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dqn paramater\n",
    "GAMMA = 0.99\n",
    "EPS_DECAY = 0.0005\n",
    "BATCH_SIZE = 64\n",
    "EPISODE_DONE = 1000\n",
    "TRAIN_FLAG = EPISODE_DONE * 10\n",
    "MEMORY_SIZE = TRAIN_FLAG * 10\n",
    "\n",
    "LEARN_FREQ = 50\n",
    "ACTION_NUM = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    [\n",
    "        tf.keras.models.load_model('./model/one_lstm/one_lstm_{0}/{1}_model'.format(j, i)) for i in range(21)\n",
    "    ]   for j in range(ACTION_NUM)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_data(origin, d):\n",
    "    shift_d = np.zeros((1, 12, 21))\n",
    "    for i in range(21):\n",
    "        d_s = d[:,i]\n",
    "        shift_d[0][:,i] = np.concatenate((origin[0][1::][:,i], d_s), axis=0).reshape(1, 12)\n",
    "    return shift_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_action(idx, s):\n",
    "    model_pred = np.zeros((5, 21, 1))\n",
    "    for i in range(5):\n",
    "        for j in range(21):\n",
    "            s_s = s[:,:,j].reshape(1, 12, 1)\n",
    "            model_pred[i][j] = model_list[i][j](s_s)[0]\n",
    "    return model_pred[idx].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_state(s, a):\n",
    "    ns = s[:,0:21] + a\n",
    "    return ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_reward(ns, gs):\n",
    "    ns_s = ns[:,0:21]\n",
    "    dist = np.sqrt(np.sum(np.square(gs - ns_s)))\n",
    "\n",
    "    end = 0\n",
    "    for i in range(21):\n",
    "        if ns_s[0][i] == gs[0][i]:\n",
    "            end += 4\n",
    "    \n",
    "    reward = -dist + end\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:  # stored as ( s, a, r, s_ ) in SumTree\n",
    "    e = 0.01\n",
    "    a = 0.8\n",
    "    beta = 0.3\n",
    "    beta_increment_per_sampling = 0.0005\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.tree = SumTree(capacity)\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def _get_priority(self, error):\n",
    "        return (np.abs(error) + self.e) ** self.a\n",
    "\n",
    "    def add(self, error, sample):\n",
    "        p = self._get_priority(error)\n",
    "        self.tree.add(p, sample)\n",
    "\n",
    "    def sample(self, n):\n",
    "        batch = []\n",
    "        a_is = []\n",
    "        segment = self.tree.total() / n\n",
    "        priorities = []\n",
    "\n",
    "        self.beta = np.min([1., self.beta + self.beta_increment_per_sampling])\n",
    "\n",
    "        for i in range(n):\n",
    "            a = segment * i\n",
    "            b = segment * (i + 1)\n",
    "\n",
    "            s = rand.uniform(a, b)\n",
    "            (a_i, p, data) = self.tree.get(s)\n",
    "            priorities.append(p)\n",
    "            batch.append(data)\n",
    "            a_is.append(a_i)\n",
    "\n",
    "        sampling_probabilities = priorities / self.tree.total()\n",
    "        is_weight = np.power(self.tree.n_entries * sampling_probabilities, -self.beta)\n",
    "        is_weight /= is_weight.max()\n",
    "\n",
    "        return batch, a_is, is_weight\n",
    "\n",
    "    def update(self, a_i, error):\n",
    "        p = self._get_priority(error)\n",
    "        self.tree.update(a_i, p)\n",
    "\n",
    "class SumTree:\n",
    "    write = 0\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "        self.n_entries = 0\n",
    "\n",
    "    # update to the root node\n",
    "    def _propagate(self, a_i, change):\n",
    "        parent = (a_i - 1) // 2\n",
    "\n",
    "        self.tree[parent] += change\n",
    "\n",
    "        if parent != 0:\n",
    "            self._propagate(parent, change)\n",
    "\n",
    "    # find sample on leaf node\n",
    "    def _retrieve(self, a_i, s):\n",
    "        left = 2 * a_i + 1\n",
    "        right = left + 1\n",
    "\n",
    "        if left >= len(self.tree):\n",
    "            return a_i\n",
    "\n",
    "        if s <= self.tree[left]:\n",
    "            return self._retrieve(left, s)\n",
    "        else:\n",
    "            return self._retrieve(right, s - self.tree[left])\n",
    "\n",
    "    def total(self):\n",
    "        return self.tree[0]\n",
    "\n",
    "    # store priority and sample\n",
    "    def add(self, p, data):\n",
    "        a_i = self.write + self.capacity - 1\n",
    "\n",
    "        self.data[self.write] = data\n",
    "        self.update(a_i, p)\n",
    "\n",
    "        self.write += 1\n",
    "        if self.write >= self.capacity:\n",
    "            self.write = 0\n",
    "\n",
    "        if self.n_entries < self.capacity:\n",
    "            self.n_entries += 1\n",
    "\n",
    "    # update priority\n",
    "    def update(self, a_i, p):\n",
    "        change = p - self.tree[a_i]\n",
    "\n",
    "        self.tree[a_i] = p\n",
    "        self._propagate(a_i, change)\n",
    "\n",
    "    # get priority and sample\n",
    "    def get(self, s):\n",
    "        a_i = self._retrieve(0, s)\n",
    "        dataa_i = a_i - self.capacity + 1\n",
    "\n",
    "        return (a_i, self.tree[a_i], self.data[dataa_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Network(tf.keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(DQN_Network, self).__init__()\n",
    "        self.input_layer = tf.keras.layers.Dense(128, activation='relu')\n",
    "\n",
    "        self.q_layer = tf.keras.models.Sequential()\n",
    "        self.q_layer.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        self.q_layer.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        self.q_layer.add(tf.keras.layers.Dense(1, activation='linear'))\n",
    "\n",
    "        self.adv_layer = tf.keras.models.Sequential()\n",
    "        self.adv_layer.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        self.adv_layer.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        self.adv_layer.add(tf.keras.layers.Dense(ACTION_NUM, activation='linear'))\n",
    "    \n",
    "    def call(self, x):\n",
    "        i = self.input_layer(x)\n",
    "\n",
    "        q = self.q_layer(i)\n",
    "        adv = self.adv_layer(i)\n",
    "\n",
    "        o = q + adv - tf.math.reduce_mean(adv, axis=1, keepdims=True)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Agent:\n",
    "    def __init__(self):\n",
    "        self.train_model = self.set_model()\n",
    "        self.target_model = self.set_model()\n",
    "        self.target_model.trainable = False\n",
    "\n",
    "        self.memory = Memory(MEMORY_SIZE)\n",
    "        self.episode = 1\n",
    "        self.eps_threshold = 1\n",
    "\n",
    "        self.optim = tf.keras.optimizers.RMSprop(learning_rate=1e-11)\n",
    "\n",
    "    def set_model(self):\n",
    "        net = DQN_Network()\n",
    "        net.build(input_shape=(1, 42))\n",
    "\n",
    "        optim = tf.keras.optimizers.RMSprop(learning_rate=1e-11)\n",
    "        net.compile(optimizer=optim, loss='mse')\n",
    "        return net\n",
    "\n",
    "    def update_model(self):\n",
    "        self.target_model.set_weights(self.train_model.get_weights())\n",
    "\n",
    "    def soft_update_model(self):\n",
    "        train_weight = np.array(self.train_model.get_weights(), dtype=object)\n",
    "        target_weight = np.array(self.target_model.get_weights(), dtype=object)\n",
    "\n",
    "        weight = train_weight * 0.01 + target_weight * 0.99\n",
    "        self.target_model.set_weights(weight)\n",
    "\n",
    "    def memorize(self, cs, a_i, r, ns, d):\n",
    "        if d and self.memory.tree.n_entries > TRAIN_FLAG:\n",
    "            self.episode += 1\n",
    "\n",
    "        td_error = r + GAMMA * np.argmax(self.target_model(ns)[0]) - np.argmax(self.train_model(cs)[0])\n",
    "        self.memory.add(td_error, (cs, a_i, r, ns, d))\n",
    "\n",
    "    def convert_memory_to_input(self, batch):\n",
    "        s, a_i, r, ns, d = zip(*batch)\n",
    "\n",
    "        states = tf.convert_to_tensor(s).reshape(BATCH_SIZE, 42)\n",
    "        action_indexs = tf.convert_to_tensor(a_i)\n",
    "        rewards = tf.convert_to_tensor(r)\n",
    "        next_states = tf.convert_to_tensor(ns).reshape(BATCH_SIZE, 42)\n",
    "        dones = tf.convert_to_tensor(d)\n",
    "\n",
    "        return states, action_indexs, rewards, next_states, dones\n",
    "\n",
    "    def act(self, state):\n",
    "        a_r = np.array(self.train_model(state))[0]\n",
    "\n",
    "        if rand.random() > self.eps_threshold:\n",
    "            a_i = np.argmax(a_r)\n",
    "            c = 1\n",
    "\n",
    "        else:\n",
    "            a_i = rand.randint(0, ACTION_NUM-1)\n",
    "            c = 0\n",
    "\n",
    "        return a_i, c, self.eps_threshold\n",
    "\n",
    "    def run(self):\n",
    "        if self.memory.tree.n_entries < TRAIN_FLAG:\n",
    "            return 1\n",
    "        \n",
    "        self.eps_threshold = 0.05 + (1 - 0.05) * math.exp(-1. * self.episode * EPS_DECAY)\n",
    "\n",
    "        batch, a_is, is_weight = self.memory.sample(BATCH_SIZE)\n",
    "\n",
    "        states, action_indexs, rewards, next_states, dones = self.convert_memory_to_input(batch)\n",
    "        is_weight = tf.convert_to_tensor(is_weight)\n",
    "        loss = self.learn(states, action_indexs, rewards, next_states, dones, is_weight)\n",
    "\n",
    "        return loss.numpy()\n",
    "\n",
    "    @tf.function\n",
    "    def learn(self, states, action_indexs, rewards, next_states, dones, is_weight):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(self.train_model.trainable_variables)\n",
    "\n",
    "            q = self.train_model(states)\n",
    "            next_q = self.train_model(next_states)\n",
    "            next_target_q = self.target_model(next_states)\n",
    "\n",
    "            next_action = tf.argmax(next_q, axis=1)\n",
    "\n",
    "            target_val = tf.reduce_sum(tf.one_hot(next_action, ACTION_NUM) * next_target_q, axis=1)\n",
    "            target_q = rewards + (1 - dones) * GAMMA * target_val\n",
    "\n",
    "            main_val = tf.reduce_sum(tf.one_hot(action_indexs, ACTION_NUM) * q, axis=1)\n",
    "\n",
    "            error = tf.square(main_val - target_val) * 0.5\n",
    "            loss = tf.reduce_mean(error)\n",
    "\n",
    "        grads = tape.gradient(loss, self.train_model.trainable_weights)\n",
    "        grads = [(tf.clip_by_value(grad, -1.0, 1.0)) for grad in grads]\n",
    "        self.optim.apply_gradients(zip(grads, self.train_model.trainable_weights))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============0=============\n",
      "=============1=============\n",
      "=============2=============\n",
      "=============3=============\n",
      "=============4=============\n",
      "=============5=============\n",
      "=============6=============\n",
      "=============7=============\n",
      "=============8=============\n",
      "=============9=============\n",
      "=============10=============\n",
      "=============11=============\n",
      "=============12=============\n",
      "=============13=============\n",
      "=============14=============\n",
      "=============15=============\n",
      "=============16=============\n",
      "=============17=============\n",
      "=============18=============\n",
      "=============19=============\n",
      "=============20=============\n",
      "=============21=============\n",
      "=============22=============\n",
      "=============23=============\n",
      "=============24=============\n",
      "=============25=============\n",
      "=============26=============\n",
      "=============27=============\n",
      "=============28=============\n",
      "=============29=============\n",
      "=============30=============\n",
      "=============31=============\n",
      "=============32=============\n",
      "=============33=============\n",
      "=============34=============\n",
      "=============35=============\n",
      "=============36=============\n",
      "=============37=============\n",
      "=============38=============\n",
      "=============39=============\n",
      "=============40=============\n",
      "=============41=============\n",
      "=============42=============\n",
      "=============43=============\n",
      "=============44=============\n",
      "=============45=============\n",
      "=============46=============\n",
      "=============47=============\n",
      "=============48=============\n",
      "=============49=============\n",
      "=============50=============\n",
      "=============51=============\n",
      "=============52=============\n",
      "=============53=============\n",
      "=============54=============\n",
      "=============55=============\n",
      "=============56=============\n",
      "=============57=============\n",
      "=============58=============\n",
      "=============59=============\n",
      "=============60=============\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m lstm_state \u001b[38;5;241m=\u001b[39m shift_data(lstm_state, state[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m21\u001b[39m])\n\u001b[0;32m     16\u001b[0m a_i, t, eps \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mact(state)\n\u001b[1;32m---> 17\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mreturn_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m checker \u001b[38;5;241m=\u001b[39m state[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m21\u001b[39m] \u001b[38;5;241m==\u001b[39m goal[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m steps \u001b[38;5;241m==\u001b[39m EPISODE_DONE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(checker[\u001b[38;5;241m0\u001b[39m]):\n",
      "Cell \u001b[1;32mIn[110], line 6\u001b[0m, in \u001b[0;36mreturn_action\u001b[1;34m(idx, s)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m21\u001b[39m):\n\u001b[0;32m      5\u001b[0m         s_s \u001b[38;5;241m=\u001b[39m s[:,:,j]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m         model_pred[i][j] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_s\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_pred[idx]\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:490\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    488\u001b[0m   layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:1010\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1007\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autocast:\n\u001b[1;32m-> 1010\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m   1014\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:2473\u001b[0m, in \u001b[0;36mLayer._maybe_cast_inputs\u001b[1;34m(self, inputs, input_list)\u001b[0m\n\u001b[0;32m   2466\u001b[0m should_autocast \u001b[39m=\u001b[39m (\n\u001b[0;32m   2467\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autocast \u001b[39mand\u001b[39;00m compute_dtype_object \u001b[39mand\u001b[39;00m\n\u001b[0;32m   2468\u001b[0m     compute_dtype_object\u001b[39m.\u001b[39mis_floating)\n\u001b[0;32m   2470\u001b[0m \u001b[39mif\u001b[39;00m (should_autocast \u001b[39mand\u001b[39;00m\n\u001b[0;32m   2471\u001b[0m     \u001b[39many\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_cast_single_input, input_list))):\n\u001b[0;32m   2472\u001b[0m   \u001b[39m# Only perform expensive `nest` operation when needed.\u001b[39;00m\n\u001b[1;32m-> 2473\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cast_single_input, inputs)\n\u001b[0;32m   2474\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2475\u001b[0m   \u001b[39mreturn\u001b[39;00m inputs\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:2486\u001b[0m, in \u001b[0;36mLayer._cast_single_input\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[39m\"\"\"Cast a single Tensor or TensorSpec to the compute dtype.\"\"\"\u001b[39;00m\n\u001b[0;32m   2485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_cast_single_input(x):\n\u001b[1;32m-> 2486\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcast(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_dtype_object)\n\u001b[0;32m   2487\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2488\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1002\u001b[0m, in \u001b[0;36mcast\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m   1000\u001b[0m   x \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(x, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1001\u001b[0m   \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m base_type:\n\u001b[1;32m-> 1002\u001b[0m     x \u001b[39m=\u001b[39m gen_math_ops\u001b[39m.\u001b[39;49mcast(x, base_type, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1003\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mis_complex \u001b[39mand\u001b[39;00m base_type\u001b[39m.\u001b[39mis_floating:\n\u001b[0;32m   1004\u001b[0m   logging\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mCasting complex to real discards imaginary part.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:1996\u001b[0m, in \u001b[0;36mcast\u001b[1;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[0;32m   1994\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   1995\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1996\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   1997\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mCast\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, x, \u001b[39m\"\u001b[39;49m\u001b[39mDstT\u001b[39;49m\u001b[39m\"\u001b[39;49m, DstT, \u001b[39m\"\u001b[39;49m\u001b[39mTruncate\u001b[39;49m\u001b[39m\"\u001b[39;49m, Truncate)\n\u001b[0;32m   1998\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   1999\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = DQN_Agent()\n",
    "state_hist = []\n",
    "reward_hist = [[] for i in range(4)]\n",
    "loss_hist = []\n",
    "eps_hist = []\n",
    "steps_list = []\n",
    "\n",
    "for e in range(20000 + TRAIN_FLAG // EPISODE_DONE):\n",
    "    state = np.array([start, goal]).reshape(1, 42)\n",
    "    steps = 1\n",
    "    reward = return_reward(state, goal)\n",
    "    rewards = 0\n",
    "\n",
    "    while True:\n",
    "        lstm_state = shift_data(lstm_state, state[:,0:21])\n",
    "        a_i, t, eps = agent.act(state)\n",
    "        action = return_action(a_i, lstm_state)\n",
    "\n",
    "        checker = state[:,0:21] == goal[0]\n",
    "        if steps == EPISODE_DONE or all(checker[0]):\n",
    "            done = 1\n",
    "        else:\n",
    "            done = 0\n",
    "\n",
    "        next_state = np.array([return_state(state, action), goal]).reshape(1, 42)\n",
    "        reward = return_reward(next_state, goal)\n",
    "\n",
    "        agent.memorize(state, a_i, reward, next_state, done)\n",
    "        if steps % LEARN_FREQ == 0:\n",
    "            loss = agent.run()\n",
    "            agent.soft_update_model()\n",
    "        \n",
    "        state = next_state\n",
    "        rewards += reward\n",
    "        steps += 1\n",
    "\n",
    "        if done:\n",
    "            rewards = rewards if steps - 1 == EPISODE_DONE else -100\n",
    "            reward_hist[0].append(rewards)\n",
    "            print(f'============={e if steps -1 == EPISODE_DONE else 0}=============')\n",
    "\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78ddfc3686b8b7161f2836984651df038ec9a0366954334fc42499f59ad2b3c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
