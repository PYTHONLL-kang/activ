{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\code\\\\activ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = 'nov_nine_var.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = tf.keras.models.load_model('./model/dnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dqn paramater\n",
    "GAMMA = 0.9\n",
    "BATCH_SIZE = 1000\n",
    "ACTION_NUM = 5\n",
    "SEQUENCE_LENGTH = 12\n",
    "EPISODE_DONE = 100\n",
    "EPS_DECAY = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_net0\n",
    "action_net1\n",
    "action_net2\n",
    "action_net3\n",
    "action_net4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# set action lstm network\n",
    "for i in range(ACTION_NUM):\n",
    "        globals()[f'action_net{i}'] = tf.keras.models.load_model('./model/action_net{0}'.format(i))\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./documents/' + df_name).iloc[:,1::]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(df.iloc[:,0:21].to_numpy())\n",
    "\n",
    "starting_state = X[-SEQUENCE_LENGTH::].reshape(1, SEQUENCE_LENGTH, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 21), dtype=float32, numpy=\n",
       "array([[ 0.046262,  1.02393 ,  0.150593,  0.981893,  0.988239,  0.997112,\n",
       "         0.000832,  0.461403,  0.034366,  0.563065,  0.104653,  0.375023,\n",
       "         0.154083,  0.266733,  0.054356,  0.181203,  0.954234, -0.013618,\n",
       "         0.446697,  0.199503,  0.939513]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_net1(starting_state.reshape(1, 12, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_goal(goal_df_name):\n",
    "    \"\"\" set goal destination\n",
    "    Args:\n",
    "        goal_df_name(str): df_name in documents/result/\n",
    "    Returns:\n",
    "        goal_state(ndArray, (1, 21)): the state of lowest rate in df\n",
    "    \"\"\"\n",
    "    goal_df = pd.read_excel('./documents/result/' + goal_df_name).iloc[:,1::].to_numpy()\n",
    "    index = goal_df[:,-1].argmin()\n",
    "\n",
    "    goal_state = goal_df[:,0:21][index]\n",
    "\n",
    "    return goal_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_action(s):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        s(ndArray, (1, SEQUENCE_LENGTH, 21)): the state\n",
    "    Returns:\n",
    "        a(ndArray, (ACTION_NUM, 21)): the action predicted by lstm\n",
    "    \"\"\"\n",
    "    data_num = s.shape[0]\n",
    "    s = s.reshape(data_num, SEQUENCE_LENGTH, 21)\n",
    "    action_list = []\n",
    "    for i in range(ACTION_NUM):\n",
    "        action = globals()[f'action_net{i}'](s)\n",
    "        action_list.append(action)\n",
    "    a = tf.convert_to_tensor(action_list, dtype=tf.float32).reshape(data_num, ACTION_NUM, 21)\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_state(s, a):\n",
    "    \"\"\" return concatenate s[1::] and a, which mean next state\n",
    "    Args:\n",
    "        s(ndArray, (1, SEQUENCE_LENGTH, 21)): the current state\n",
    "        a(ndArray, (1, 21)): the action on the current state\n",
    "    Returns:\n",
    "        ns(ndArray, (1, SEQENCE_LENGTH, 21)): the next state\n",
    "    \"\"\"\n",
    "    ns = np.concatenate((s[0][1::], a), axis=0).reshape(1, SEQUENCE_LENGTH, 21)\n",
    "    return ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_reward(ns, gs):\n",
    "    \"\"\" evaluate current action\n",
    "    Args:\n",
    "        ns(ndArray, (1, SEQUENCE_LENGTH, 21)): the consequence of action in the current state\n",
    "        gs(ndArray, (1, 21)): the destination\n",
    "    Returns:\n",
    "        reward(int): distance to destination + reality of action possible\n",
    "    \"\"\"\n",
    "    gs = scaler.transform(gs)\n",
    "    dist = np.sqrt(np.sum(np.square(gs - ns[0][-1])))\n",
    "    loss = dist\n",
    "    \n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Network(tf.keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(DQN_Network, self).__init__()\n",
    "        self.input_layer = tf.keras.layers.Dense(128, input_shape=(ACTION_NUM, 21), activation='relu')\n",
    "\n",
    "        self.hidden_layer = tf.keras.models.Sequential()\n",
    "        self.hidden_layer.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        self.hidden_layer.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "        self.ouput_layer = tf.keras.layers.Dense(1, activation='linear')\n",
    "\n",
    "    def call(self, s):\n",
    "        x = return_action(s)\n",
    "        i = self.input_layer(x)\n",
    "        h = self.hidden_layer(i)\n",
    "        o = self.ouput_layer(h)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Agent:\n",
    "    def __init__(self):\n",
    "        self.train_model = self.set_model()\n",
    "        self.target_model = self.set_model()\n",
    "\n",
    "        self.memory = deque(maxlen=20000)\n",
    "        self.episode = 1\n",
    "\n",
    "        self.optim = tf.keras.optimizers.Adam(learning_rate=1e-10)\n",
    "        self.loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    def set_model(self):\n",
    "        net = DQN_Network()\n",
    "        net.build(input_shape=(1, SEQUENCE_LENGTH, 21))\n",
    "\n",
    "        optim = tf.keras.optimizers.Adam(learning_rate=1e-10)\n",
    "        net.compile(optimizer=optim, loss='mse')\n",
    "        return net\n",
    "\n",
    "    def memorize(self, cs, a, a_i, r, ns, d):\n",
    "        \"\"\" append to self.memory\n",
    "        Args:\n",
    "            cs(ndArray, (1, SEQUENCE_LENGTH, 21)): the current state\n",
    "            a(ndArray, (1, 21)): the action on current state\n",
    "            a_i(int): the index of the action chosen by the agent\n",
    "            r(int): reward for action in the current state\n",
    "            ns(ndArray, (1, SEQUENCE_LENGTH, 21)): the next state\n",
    "            d(boolean): whether to proceed with the episode\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if d:\n",
    "            self.episode += 1\n",
    "        \n",
    "        self.memory.append(\n",
    "            (\n",
    "                tf.convert_to_tensor(tf.cast(cs, tf.float32)),\n",
    "                tf.convert_to_tensor(tf.cast(a, tf.float32)),\n",
    "                a_i,\n",
    "                tf.convert_to_tensor(tf.cast(r, tf.float32)),\n",
    "                tf.convert_to_tensor(tf.cast(ns, tf.float32)),\n",
    "                d\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def convert_memory_to_input(self):\n",
    "        batch = rand.sample(self.memory, BATCH_SIZE)\n",
    "        s, a, a_i, r, ns, d = zip(*batch)\n",
    "\n",
    "        states = tf.convert_to_tensor(s).reshape(BATCH_SIZE, SEQUENCE_LENGTH, 21)\n",
    "        actions = tf.convert_to_tensor(a).reshape(BATCH_SIZE, 21)\n",
    "        action_indexs = tf.convert_to_tensor(a_i)\n",
    "        rewards = tf.convert_to_tensor(r)\n",
    "        next_states = tf.convert_to_tensor(ns).reshape(BATCH_SIZE, SEQUENCE_LENGTH, 21)\n",
    "        dones = tf.convert_to_tensor(d)\n",
    "\n",
    "        return states, actions, action_indexs, rewards, next_states, dones\n",
    "\n",
    "    def act(self, state):\n",
    "        # if self.episode >= 0 and self.episode < 200:\n",
    "        #     eps_threshold = -(self.episode/1000)+1+(self.episode)*(self.episode-200)/300000\n",
    "        # else:\n",
    "        #     eps_threshold = -(self.episode/1000)+1+(self.episode-200)*(self.episode-1000)\n",
    "\n",
    "        eps_threshold = EPS_DECAY ** self.episode\n",
    "\n",
    "        a = return_action(state)\n",
    "        r = self.train_model(state)\n",
    "\n",
    "        if rand.random() > eps_threshold:\n",
    "            a_i = np.argmax(r)\n",
    "        else:\n",
    "            a_i = rand.randint(0, ACTION_NUM-1)\n",
    "\n",
    "        return a[0][a_i].reshape(1, 21), a_i, eps_threshold\n",
    "\n",
    "    def run(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return 1\n",
    "\n",
    "        states, actions, action_indexs, rewards, next_states, dones = self.convert_memory_to_input()\n",
    "        loss = self.learn(states, actions, action_indexs, rewards, next_states, dones)\n",
    "    \n",
    "        return loss.numpy()\n",
    "        \n",
    "    @tf.function\n",
    "    def learn(self, states, actions, action_indexs, rewards, next_states, dones):\n",
    "        target_q = self.target_model(next_states)\n",
    "\n",
    "        q_target = rewards + (1 - dones) * GAMMA * tf.reduce_max(target_q, axis=1, keepdims=True)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            current_q = self.train_model(states) # 현재 상황에서 할 수 있는 행동들의 q value\n",
    "            current_q = tf.reduce_sum(current_q[action_indexs], axis=1, keepdims=True) # 실제 한 행동에 대한 q value\n",
    "\n",
    "            loss = self.loss_fn(current_q, q_target)\n",
    "        grads = tape.gradient(loss, self.train_model.trainable_weights)\n",
    "        self.optim.apply_gradients(zip(grads, self.train_model.trainable_weights))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 10, reward: -1.8894538885112586\n",
      "steps: 20, reward: -1.8603057360000046\n",
      "steps: 30, reward: -1.791429627661269\n",
      "steps: 40, reward: -1.7887223102579373\n",
      "steps: 50, reward: -1.8369469918867547\n",
      "steps: 60, reward: -1.833842680638964\n",
      "steps: 70, reward: -1.8314609136105036\n",
      "steps: 80, reward: -1.8238000963259973\n",
      "steps: 90, reward: -1.8047622650893758\n",
      "steps: 100, reward: -1.8276757433106026\n",
      "=============0=============\n",
      "-183.855 1 24 0.99\n",
      "=============================\n",
      "steps: 10, reward: -1.8512855622890987\n",
      "steps: 20, reward: -1.7858737821359179\n",
      "steps: 30, reward: -1.8495713266812093\n",
      "steps: 40, reward: -1.8206204751011632\n",
      "steps: 50, reward: -1.874459242271671\n",
      "steps: 60, reward: -1.8285099411167813\n",
      "steps: 70, reward: -1.8529636384490908\n",
      "steps: 80, reward: -1.8901231585821592\n",
      "steps: 90, reward: -1.8994413378992538\n",
      "steps: 100, reward: -1.7661412806486152\n",
      "=============1=============\n",
      "-186.919 1 27 0.9801\n",
      "=============================\n",
      "steps: 10, reward: -1.8524590853236418\n",
      "steps: 20, reward: -1.8953297726305274\n",
      "steps: 30, reward: -1.8343793713886412\n",
      "steps: 40, reward: -1.8836887692831898\n",
      "steps: 50, reward: -1.9023072655387039\n",
      "steps: 60, reward: -1.8196851428700167\n",
      "steps: 70, reward: -1.7647133541457534\n",
      "steps: 80, reward: -1.9190315149390595\n",
      "steps: 90, reward: -1.8587713526663916\n",
      "steps: 100, reward: -1.8484953059590115\n",
      "=============2=============\n",
      "-186.531 1 28 0.9703\n",
      "=============================\n",
      "steps: 10, reward: -1.8021674480309735\n",
      "steps: 20, reward: -1.7898115861367034\n",
      "steps: 30, reward: -1.798197799288586\n",
      "steps: 40, reward: -1.8184268985525471\n",
      "steps: 50, reward: -1.7731481534526512\n",
      "steps: 60, reward: -1.787475092879339\n",
      "steps: 70, reward: -1.862928983334427\n",
      "steps: 80, reward: -1.8212408681331977\n",
      "steps: 90, reward: -1.7396298435458777\n",
      "steps: 100, reward: -1.822294162597329\n",
      "=============3=============\n",
      "-182.398 1 31 0.9606\n",
      "=============================\n",
      "steps: 10, reward: -1.8420570831905645\n",
      "steps: 20, reward: -1.8842424639565483\n",
      "steps: 30, reward: -1.8430741206528964\n",
      "steps: 40, reward: -1.8765936343560037\n",
      "steps: 50, reward: -1.765609070732476\n",
      "steps: 60, reward: -1.842554391530406\n",
      "steps: 70, reward: -1.7602972068741485\n",
      "steps: 80, reward: -1.8442671326408475\n",
      "steps: 90, reward: -1.7567768331882219\n",
      "steps: 100, reward: -1.8699092126754804\n",
      "=============4=============\n",
      "-185.076 1 31 0.95099\n",
      "=============================\n",
      "steps: 10, reward: -1.8078201894247712\n",
      "steps: 20, reward: -1.7666264458623027\n",
      "steps: 30, reward: -1.8947704421832394\n",
      "steps: 40, reward: -1.8184240515241203\n",
      "steps: 50, reward: -1.8672062548169073\n",
      "steps: 60, reward: -1.752415081286713\n",
      "steps: 70, reward: -1.8101437692287563\n",
      "steps: 80, reward: -1.8506995813694593\n",
      "steps: 90, reward: -1.8494101155453007\n",
      "steps: 100, reward: -1.8069801737402043\n",
      "=============5=============\n",
      "-185.196 1 26 0.94148\n",
      "=============================\n",
      "steps: 10, reward: -1.787378435051823\n",
      "steps: 20, reward: -1.8338913874773766\n",
      "steps: 30, reward: -1.856187150588686\n",
      "steps: 40, reward: -1.851925457798463\n",
      "steps: 50, reward: -1.7353748279583738\n",
      "steps: 60, reward: -1.8160386897953709\n",
      "steps: 70, reward: -1.7398820212829123\n",
      "steps: 80, reward: -1.8216037400999783\n",
      "steps: 90, reward: -1.7261574262514148\n",
      "steps: 100, reward: -1.7717310075182893\n",
      "=============6=============\n",
      "-182.912 1 29 0.93207\n",
      "=============================\n",
      "steps: 10, reward: -1.8854059398283398\n",
      "steps: 20, reward: -1.868152166467671\n",
      "steps: 30, reward: -1.8625119938134196\n",
      "steps: 40, reward: -1.8445186721554212\n",
      "steps: 50, reward: -1.712110042540582\n",
      "steps: 60, reward: -1.764300836163781\n",
      "steps: 70, reward: -1.8281426212702052\n",
      "steps: 80, reward: -1.716797859662908\n",
      "steps: 90, reward: -1.7329459423623537\n",
      "steps: 100, reward: -1.7739021310941787\n",
      "=============7=============\n",
      "-181.006 1 33 0.92274\n",
      "=============================\n",
      "steps: 10, reward: -1.8369519651563881\n",
      "steps: 20, reward: -1.8261981112875056\n",
      "steps: 30, reward: -1.813784780707078\n",
      "steps: 40, reward: -1.8115133791652773\n",
      "steps: 50, reward: -1.8376361227407363\n",
      "steps: 60, reward: -1.829663368678171\n",
      "steps: 70, reward: -1.8485295353787303\n",
      "steps: 80, reward: -1.8272943517954112\n",
      "steps: 90, reward: -1.7968600229188139\n",
      "steps: 100, reward: -1.7574358434099855\n",
      "=============8=============\n",
      "-184.105 1 24 0.91352\n",
      "=============================\n",
      "steps: 10, reward: -1.8162793278595444\n",
      "steps: 20, reward: -1.8959322293785128\n",
      "steps: 30, reward: -1.866779131847065\n",
      "steps: 40, reward: -1.9152390994536785\n",
      "steps: 50, reward: -1.7732222376034144\n",
      "steps: 60, reward: -1.8247528470620007\n",
      "steps: 70, reward: -1.9038694182868547\n",
      "steps: 80, reward: -1.8437946900317408\n",
      "steps: 90, reward: -1.744031137212429\n",
      "steps: 100, reward: -1.8305189578054355\n",
      "=============9=============\n",
      "-185.449 2.511 23 0.90438\n",
      "=============================\n",
      "steps: 10, reward: -1.8509688146998586\n",
      "steps: 20, reward: -1.7676142553877845\n",
      "steps: 30, reward: -1.8857405464327397\n",
      "steps: 40, reward: -1.8021258541723644\n",
      "steps: 50, reward: -1.8440344964882887\n",
      "steps: 60, reward: -1.7364823741172914\n",
      "steps: 70, reward: -1.8604818887791037\n",
      "steps: 80, reward: -1.8879168640154966\n",
      "steps: 90, reward: -1.8542884077337494\n",
      "steps: 100, reward: -1.878386390339966\n",
      "=============10=============\n",
      "-184.489 2.51 28 0.89534\n",
      "=============================\n",
      "steps: 10, reward: -1.7632110935671022\n",
      "steps: 20, reward: -1.7677330589543658\n",
      "steps: 30, reward: -1.835361951108418\n",
      "steps: 40, reward: -1.8524923614184619\n",
      "steps: 50, reward: -1.8681240477466698\n",
      "steps: 60, reward: -1.8662375652241279\n",
      "steps: 70, reward: -1.8439163962320728\n",
      "steps: 80, reward: -1.8002501417531644\n",
      "steps: 90, reward: -1.845899441646839\n",
      "steps: 100, reward: -1.854350950297307\n",
      "=============11=============\n",
      "-184.234 2.508 26 0.88638\n",
      "=============================\n",
      "steps: 10, reward: -1.8823611168783414\n",
      "steps: 20, reward: -1.8254112605314288\n",
      "steps: 30, reward: -1.8255525856175674\n",
      "steps: 40, reward: -1.8308925621394312\n",
      "steps: 50, reward: -1.8364719476798732\n",
      "steps: 60, reward: -1.7371552145456306\n",
      "steps: 70, reward: -1.8345241457727992\n",
      "steps: 80, reward: -1.8482751050238047\n",
      "steps: 90, reward: -1.7243309948482384\n",
      "steps: 100, reward: -1.7307528997162067\n",
      "=============12=============\n",
      "-183.009 2.506 28 0.87752\n",
      "=============================\n",
      "steps: 10, reward: -1.8800189223276578\n",
      "steps: 20, reward: -1.8494040897582096\n",
      "steps: 30, reward: -1.7217824492554412\n",
      "steps: 40, reward: -1.8133172499878898\n",
      "steps: 50, reward: -1.7789513832425614\n",
      "steps: 60, reward: -1.7177101249953866\n",
      "steps: 70, reward: -1.7388509901735216\n",
      "steps: 80, reward: -1.8226646330109104\n",
      "steps: 90, reward: -1.8476449299584217\n",
      "steps: 100, reward: -1.8360247451740817\n",
      "=============13=============\n",
      "-182.368 2.503 29 0.86875\n",
      "=============================\n",
      "steps: 10, reward: -1.7654134282986333\n",
      "steps: 20, reward: -1.876082975358248\n",
      "steps: 30, reward: -1.862931072251526\n",
      "steps: 40, reward: -1.7473860106464323\n",
      "steps: 50, reward: -1.8605227549232126\n",
      "steps: 60, reward: -1.8912454912761498\n",
      "steps: 70, reward: -1.8791274579892154\n",
      "steps: 80, reward: -1.8176688619102859\n",
      "steps: 90, reward: -1.8787315040770516\n",
      "steps: 100, reward: -1.7660106327325595\n",
      "=============14=============\n",
      "-185.089 2.499 29 0.86006\n",
      "=============================\n",
      "steps: 10, reward: -1.8583769707450766\n",
      "steps: 20, reward: -1.8666185717340833\n",
      "steps: 30, reward: -1.8384777709483342\n",
      "steps: 40, reward: -1.8709522906545804\n",
      "steps: 50, reward: -1.7547811787613306\n",
      "steps: 60, reward: -1.8507035978235484\n",
      "steps: 70, reward: -1.8112013734368433\n",
      "steps: 80, reward: -1.740480629663541\n",
      "steps: 90, reward: -1.840665720455418\n",
      "steps: 100, reward: -1.8360717066168866\n",
      "=============15=============\n",
      "-184.308 2.508 28 0.85146\n",
      "=============================\n",
      "steps: 10, reward: -1.8026336423350675\n",
      "steps: 20, reward: -1.7380575868652826\n",
      "steps: 30, reward: -1.7330019673510644\n",
      "steps: 40, reward: -1.8158205078589682\n",
      "steps: 50, reward: -1.7375169007768418\n",
      "steps: 60, reward: -1.8334575374627793\n",
      "steps: 70, reward: -1.8260420555255623\n",
      "steps: 80, reward: -1.7894013210920303\n",
      "steps: 90, reward: -1.769924304568562\n",
      "steps: 100, reward: -1.727572305855715\n",
      "=============16=============\n",
      "-181.349 2.496 40 0.84294\n",
      "=============================\n",
      "steps: 10, reward: -1.8402293770843177\n",
      "steps: 20, reward: -1.8885863952014408\n",
      "steps: 30, reward: -1.874254784788219\n",
      "steps: 40, reward: -1.812669248514899\n",
      "steps: 50, reward: -1.745449453272328\n",
      "steps: 60, reward: -1.829671141331419\n",
      "steps: 70, reward: -1.8380780478724619\n",
      "steps: 80, reward: -1.8483323628480468\n",
      "steps: 90, reward: -1.7474922223100042\n",
      "steps: 100, reward: -1.7500660015122957\n",
      "=============17=============\n",
      "-182.95 2.494 35 0.83451\n",
      "=============================\n",
      "steps: 10, reward: -1.7991297325337936\n",
      "steps: 20, reward: -1.7406670952294734\n",
      "steps: 30, reward: -1.7182199457229483\n",
      "steps: 40, reward: -1.8110363598697081\n",
      "steps: 50, reward: -1.8585613626556652\n",
      "steps: 60, reward: -1.8265291482512533\n",
      "steps: 70, reward: -1.7859494796217477\n",
      "steps: 80, reward: -1.8476491941027329\n",
      "steps: 90, reward: -1.8289224500055141\n",
      "steps: 100, reward: -1.8141387961324393\n",
      "=============18=============\n",
      "-182.809 2.489 40 0.82617\n",
      "=============================\n",
      "steps: 10, reward: -1.7748882111690931\n",
      "steps: 20, reward: -1.8082290542046506\n",
      "steps: 30, reward: -1.859060013504909\n",
      "steps: 40, reward: -1.8432531794940148\n",
      "steps: 50, reward: -1.8355966148007776\n",
      "steps: 60, reward: -1.7284417099145157\n",
      "steps: 70, reward: -1.7302949286684788\n",
      "steps: 80, reward: -1.8340151885392428\n",
      "steps: 90, reward: -1.8619053774852354\n",
      "steps: 100, reward: -1.837293222195464\n",
      "=============19=============\n",
      "-183.207 2.489 27 0.81791\n",
      "=============================\n",
      "steps: 10, reward: -1.841178141858127\n",
      "steps: 20, reward: -1.9018473809223473\n",
      "steps: 30, reward: -1.9270311888970009\n",
      "steps: 40, reward: -1.7581182883462225\n",
      "steps: 50, reward: -1.8702091207076734\n",
      "steps: 60, reward: -1.8399563927524858\n",
      "steps: 70, reward: -1.849540573624314\n",
      "steps: 80, reward: -1.8002874994549085\n",
      "steps: 90, reward: -1.8012853192756682\n",
      "steps: 100, reward: -1.7431174868069692\n",
      "=============20=============\n",
      "-185.297 2.501 28 0.80973\n",
      "=============================\n",
      "steps: 10, reward: -1.8842776925049214\n",
      "steps: 20, reward: -1.7976185169112655\n",
      "steps: 30, reward: -1.8055864194328206\n",
      "steps: 40, reward: -1.808875650654948\n",
      "steps: 50, reward: -1.859443609433332\n",
      "steps: 60, reward: -1.827650760913823\n",
      "steps: 70, reward: -1.843475946473755\n",
      "steps: 80, reward: -1.8615306568714018\n",
      "steps: 90, reward: -1.807632336772318\n",
      "steps: 100, reward: -1.8850414119194736\n",
      "=============21=============\n",
      "-183.911 2.491 35 0.80163\n",
      "=============================\n",
      "steps: 10, reward: -1.761991106727683\n",
      "steps: 20, reward: -1.8504001619884187\n",
      "steps: 30, reward: -1.8084015346606974\n",
      "steps: 40, reward: -1.7443881720011292\n",
      "steps: 50, reward: -1.753065188017205\n",
      "steps: 60, reward: -1.8128601217202873\n",
      "steps: 70, reward: -1.8193553793625659\n",
      "steps: 80, reward: -1.6859870979180986\n",
      "steps: 90, reward: -1.7968523525947315\n",
      "steps: 100, reward: -1.8222714301848084\n",
      "=============22=============\n",
      "-181.417 2.49 30 0.79361\n",
      "=============================\n",
      "steps: 10, reward: -1.757948434210551\n",
      "steps: 20, reward: -1.8107365149030448\n",
      "steps: 30, reward: -1.8037964118423107\n",
      "steps: 40, reward: -1.8509835312688363\n",
      "steps: 50, reward: -1.8446682420787006\n",
      "steps: 60, reward: -1.7477926447638719\n",
      "steps: 70, reward: -1.8006874659805765\n",
      "steps: 80, reward: -1.835570009455338\n",
      "steps: 90, reward: -1.8336406946835664\n",
      "steps: 100, reward: -1.7889957748118575\n",
      "=============23=============\n",
      "-182.766 2.493 39 0.78568\n",
      "=============================\n",
      "steps: 10, reward: -1.8838266046995633\n",
      "steps: 20, reward: -1.8296772500033025\n",
      "steps: 30, reward: -1.8557101516214976\n",
      "steps: 40, reward: -1.8344092156224425\n",
      "steps: 50, reward: -1.836560031208194\n",
      "steps: 60, reward: -1.8513851278883064\n",
      "steps: 70, reward: -1.8457895050724382\n",
      "steps: 80, reward: -1.7497435922020077\n",
      "steps: 90, reward: -1.822656533257944\n",
      "steps: 100, reward: -1.8384026215069995\n",
      "=============24=============\n",
      "-182.807 2.492 36 0.77782\n",
      "=============================\n",
      "steps: 10, reward: -1.7998951125509648\n",
      "steps: 20, reward: -1.7291368523892419\n",
      "steps: 30, reward: -1.848754063259775\n",
      "steps: 40, reward: -1.8623600181459343\n",
      "steps: 50, reward: -1.8415595885195577\n",
      "steps: 60, reward: -1.810778871664922\n",
      "steps: 70, reward: -1.7926123258115012\n",
      "steps: 80, reward: -1.785797061194426\n",
      "steps: 90, reward: -1.8257302459644162\n",
      "steps: 100, reward: -1.816979275648919\n",
      "=============25=============\n",
      "-183.017 2.482 37 0.77004\n",
      "=============================\n",
      "steps: 10, reward: -1.8360935943117744\n",
      "steps: 20, reward: -1.8154641452870428\n",
      "steps: 30, reward: -1.7586224255447147\n",
      "steps: 40, reward: -1.8493130407129754\n",
      "steps: 50, reward: -1.8112579804567819\n",
      "steps: 60, reward: -1.8266223602442453\n",
      "steps: 70, reward: -1.8008014202406162\n",
      "steps: 80, reward: -1.797847283568502\n",
      "steps: 90, reward: -1.8421420300995521\n",
      "steps: 100, reward: -1.7352557081551123\n",
      "=============26=============\n",
      "-184.246 2.485 31 0.76234\n",
      "=============================\n",
      "steps: 10, reward: -1.8092426823767667\n",
      "steps: 20, reward: -1.8416409301366323\n",
      "steps: 30, reward: -1.8284510176864892\n",
      "steps: 40, reward: -1.7568985305905225\n",
      "steps: 50, reward: -1.7917106463678432\n",
      "steps: 60, reward: -1.7974982440279337\n",
      "steps: 70, reward: -1.8235324994310367\n",
      "steps: 80, reward: -1.8374369732513953\n",
      "steps: 90, reward: -1.7963080060097236\n",
      "steps: 100, reward: -1.8418455820566924\n",
      "=============27=============\n",
      "-182.147 2.485 48 0.75472\n",
      "=============================\n",
      "steps: 10, reward: -1.7961976324887698\n",
      "steps: 20, reward: -1.8114595624362957\n",
      "steps: 30, reward: -1.7800657301077074\n",
      "steps: 40, reward: -1.8219027528693463\n",
      "steps: 50, reward: -1.7998748590869733\n",
      "steps: 60, reward: -1.7325387295471664\n",
      "steps: 70, reward: -1.7225576843119632\n",
      "steps: 80, reward: -1.7628184679134107\n",
      "steps: 90, reward: -1.763683507436324\n",
      "steps: 100, reward: -1.7659359686257434\n",
      "=============28=============\n",
      "-180.245 2.488 45 0.74717\n",
      "=============================\n",
      "steps: 10, reward: -1.8183000792082908\n",
      "steps: 20, reward: -1.8539746452707555\n",
      "steps: 30, reward: -1.872401680816197\n",
      "steps: 40, reward: -1.8137840017697657\n",
      "steps: 50, reward: -1.8435677021227679\n",
      "steps: 60, reward: -1.7492879392860052\n",
      "steps: 70, reward: -1.7836351709374976\n",
      "steps: 80, reward: -1.72144396927637\n",
      "steps: 90, reward: -1.8161127702713253\n",
      "steps: 100, reward: -1.7902939448837216\n",
      "=============29=============\n",
      "-182.773 2.484 43 0.7397\n",
      "=============================\n",
      "steps: 10, reward: -1.7958343912487922\n",
      "steps: 20, reward: -1.7287900350798\n",
      "steps: 30, reward: -1.7249229077217667\n",
      "steps: 40, reward: -1.7243218615680724\n",
      "steps: 50, reward: -1.757536392671685\n",
      "steps: 60, reward: -1.781093881095758\n",
      "steps: 70, reward: -1.8383007374947116\n",
      "steps: 80, reward: -1.7849251886727597\n",
      "steps: 90, reward: -1.7713160031384776\n",
      "steps: 100, reward: -1.7945144335301106\n",
      "=============30=============\n",
      "-180.461 2.476 48 0.7323\n",
      "=============================\n",
      "steps: 10, reward: -1.8349205027856763\n",
      "steps: 20, reward: -1.7555838391462153\n",
      "steps: 30, reward: -1.7316993437236767\n",
      "steps: 40, reward: -1.7949826568129816\n",
      "steps: 50, reward: -1.77733592108179\n",
      "steps: 60, reward: -1.8122985191598444\n",
      "steps: 70, reward: -1.817497198569228\n",
      "steps: 80, reward: -1.713029750451746\n",
      "steps: 90, reward: -1.7843283158971521\n",
      "steps: 100, reward: -1.8252346315608614\n",
      "=============31=============\n",
      "-180.987 2.475 36 0.72498\n",
      "=============================\n",
      "steps: 10, reward: -1.8034518206518353\n",
      "steps: 20, reward: -1.8087964141752815\n",
      "steps: 30, reward: -1.7962478944955054\n",
      "steps: 40, reward: -1.8225705300549033\n",
      "steps: 50, reward: -1.7926539356747082\n",
      "steps: 60, reward: -1.825438910248747\n",
      "steps: 70, reward: -1.8403832744354827\n",
      "steps: 80, reward: -1.7940771512207825\n",
      "steps: 90, reward: -1.7822618519954962\n",
      "steps: 100, reward: -1.824372696558406\n",
      "=============32=============\n",
      "-182.271 2.474 49 0.71773\n",
      "=============================\n",
      "steps: 10, reward: -1.9043525385178581\n",
      "steps: 20, reward: -1.7668279898919361\n",
      "steps: 30, reward: -1.8356713036528813\n",
      "steps: 40, reward: -1.831468666080458\n",
      "steps: 50, reward: -1.813211807063383\n",
      "steps: 60, reward: -1.8371497072359997\n",
      "steps: 70, reward: -1.8578974858121962\n",
      "steps: 80, reward: -1.7349123781345075\n",
      "steps: 90, reward: -1.7839609789816213\n",
      "steps: 100, reward: -1.7733804438340788\n",
      "=============33=============\n",
      "-183.821 2.473 37 0.71055\n",
      "=============================\n",
      "steps: 10, reward: -1.764885061434011\n",
      "steps: 20, reward: -1.7401921217555971\n",
      "steps: 30, reward: -1.824839131263778\n",
      "steps: 40, reward: -1.7902036054601447\n",
      "steps: 50, reward: -1.8501081734543392\n",
      "steps: 60, reward: -1.8014900747186564\n",
      "steps: 70, reward: -1.790487893619477\n",
      "steps: 80, reward: -1.832118017251372\n",
      "steps: 90, reward: -1.7983552928710458\n",
      "steps: 100, reward: -1.826305832657825\n",
      "=============34=============\n",
      "-182.154 2.481 45 0.70345\n",
      "=============================\n",
      "steps: 10, reward: -1.8449173739707116\n",
      "steps: 20, reward: -1.87767613508677\n",
      "steps: 30, reward: -1.7568190557303367\n",
      "steps: 40, reward: -1.794878640541575\n",
      "steps: 50, reward: -1.8235209250468243\n",
      "steps: 60, reward: -1.8137293016136418\n",
      "steps: 70, reward: -1.7770844900479847\n",
      "steps: 80, reward: -1.7775691948253785\n",
      "steps: 90, reward: -1.7776251669864016\n",
      "steps: 100, reward: -1.7709131948134362\n",
      "=============35=============\n",
      "-181.406 2.476 51 0.69641\n",
      "=============================\n",
      "steps: 10, reward: -1.8054800349537103\n",
      "steps: 20, reward: -1.8179880596172189\n",
      "steps: 30, reward: -1.8498740925410073\n",
      "steps: 40, reward: -1.8044689314977829\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     26\u001b[0m agent\u001b[38;5;241m.\u001b[39mmemorize(state, action, idx, reward, next_state, done)\n\u001b[1;32m---> 27\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     30\u001b[0m rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[20], line 82\u001b[0m, in \u001b[0;36mDQN_Agent.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     81\u001b[0m states, actions, action_indexs, rewards, next_states, dones \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_memory_to_input()\n\u001b[1;32m---> 82\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_indexs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdones\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = DQN_Agent()\n",
    "rewards_hist = []\n",
    "st_hist = []\n",
    "\n",
    "goal_state = set_goal('basic_formula.xlsx').reshape(1, 21)\n",
    "for e in range(10000):\n",
    "    counter = [0 for i in range(ACTION_NUM)]\n",
    "    state = starting_state\n",
    "    steps = 0\n",
    "    rewards = 0\n",
    "\n",
    "    if e % 50 == 0:\n",
    "        agent.target_model.set_weights(agent.train_model.get_weights())\n",
    "\n",
    "    while True:\n",
    "        action, idx, eps = agent.act(state)\n",
    "        counter[idx] += 1\n",
    "        next_state = return_state(state, action)\n",
    "        reward = return_reward(next_state, goal_state)\n",
    "\n",
    "        if steps == EPISODE_DONE or all(state[0][-1][i] == goal_state[0][i] for i in range(21)):\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        agent.memorize(state, action, idx, reward, next_state, done)\n",
    "        loss = agent.run()\n",
    "\n",
    "        state = next_state\n",
    "        rewards += reward\n",
    "        steps += 1\n",
    "\n",
    "        if steps % 10 == 0:\n",
    "            print(f'steps: {steps}, reward: {reward}')\n",
    "\n",
    "        if done:\n",
    "            print(f'============={e}=============')\n",
    "            print(round(rewards, 3), round(loss, 3), max(counter), round(eps, 5))\n",
    "            print(\"=============================\")\n",
    "            rewards_hist.append(rewards)\n",
    "            st_hist.append(state)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17d6abace80>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78ddfc3686b8b7161f2836984651df038ec9a0366954334fc42499f59ad2b3c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
