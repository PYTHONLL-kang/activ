{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = pd.read_excel('./documents/nov_nine_var.xlsx').to_numpy()\n",
    "goal_data = pd.read_excel('./documents/result/basic_formula.xlsx').to_numpy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(real_data[:,1:22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data, i):\n",
    "    data = scaler.transform(data[:,1:22])[i].reshape(1, 21)\n",
    "\n",
    "    return np.round(data, 2)\n",
    "\n",
    "def argmax(l):\n",
    "    return max(range(len(l)), key=lambda i: l[i])\n",
    "\n",
    "def argmin(l):\n",
    "    return min(range(len(l)), key=lambda i: l[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51 0.5  0.5  0.49 0.5  0.5  0.5  0.5  0.5  0.5  0.49 0.5  0.5  0.5\n",
      " 0.5  0.5  0.49 0.49 0.51 0.5  0.5 ]\n",
      "[0.   0.98 0.   1.   0.99 1.   0.   0.78 0.09 0.46 0.4  0.58 0.27 0.32\n",
      " 0.23 0.23 1.   0.03 0.5  0.43 1.  ]\n",
      "689\n"
     ]
    }
   ],
   "source": [
    "start = load_data(real_data, -1)\n",
    "goal = load_data(goal_data, argmin(goal_data[:,-1]))\n",
    "\n",
    "print(goal[0])\n",
    "print(start[0])\n",
    "\n",
    "need_step = int(np.sum(abs(goal-start))*100)\n",
    "print(need_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor-critic hyperparmater\n",
    "GAMMA = 0.99\n",
    "EPISODE_DONE = need_step * 10\n",
    "EPS = np.finfo(np.float32).eps.item()\n",
    "ACTION_NUM = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_action(i):\n",
    "    a = np.zeros((1, 21))\n",
    "    j = i // 2\n",
    "\n",
    "    if i % 2 == 0:\n",
    "        a[0][j] = -0.01\n",
    "    \n",
    "    else:\n",
    "        a[0][j] = 0.01\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_state(s, a):\n",
    "    ns = s + a\n",
    "    return ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_reward(ns, gs):\n",
    "    dist = np.sqrt(np.sum(np.square(gs - ns)))\n",
    "\n",
    "    end = 0\n",
    "    for i in range(21):\n",
    "        if ns[0][i] == gs[0][i]:\n",
    "            end += 5\n",
    "    \n",
    "    reward = -dist + end\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor_Critic(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_layer = tf.keras.models.Sequential()\n",
    "        self.input_layer.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        self.input_layer.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "        self.actor_layer = tf.keras.models.Sequential()\n",
    "        self.actor_layer.add(tf.keras.layers.Dense(ACTION_NUM, activation='softmax'))\n",
    "\n",
    "        self.critic_layer = tf.keras.models.Sequential()\n",
    "        self.critic_layer.add(tf.keras.layers.Dense(1, activation='linear'))\n",
    "\n",
    "    def call(self, x):\n",
    "        i = self.input_layer(x)\n",
    "\n",
    "        a = self.actor_layer(i)\n",
    "        c = self.critic_layer(i)\n",
    "\n",
    "        return a, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AC_agent:\n",
    "    def __init__(self):\n",
    "        self.model = Actor_Critic()\n",
    "        self.optim = tf.keras.optimizers.Adam(learning_rate=1e-10)\n",
    "\n",
    "        self.huber_loss = tf.keras.losses.Huber()\n",
    "\n",
    "    def expected_q(self, rewards):\n",
    "        discounted_sum = 0\n",
    "        returns = np.zeros_like(rewards)\n",
    "        for i, r in enumerate(rewards):\n",
    "            discounted_sum = r + GAMMA * discounted_sum\n",
    "            returns[i] = discounted_sum\n",
    "        returns = (returns - np.mean(returns)) / (np.std(returns) + EPS)\n",
    "\n",
    "        return returns.tolist()\n",
    "\n",
    "    def act(self, state):\n",
    "        action_prob, value = self.model(state)\n",
    "        action = np.random.choice(ACTION_NUM, p=np.squeeze(action_prob))\n",
    "\n",
    "        return action, action_prob, value\n",
    "\n",
    "    def run(self, state, rewards, steps):\n",
    "        returns = self.expected_q(rewards)\n",
    "\n",
    "        states = tf.convert_to_tensor(state).reshape(steps-1, 21)\n",
    "        returns = tf.convert_to_tensor(returns)\n",
    "\n",
    "        loss = self.learn(states, returns)\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def learn(self, s, r):\n",
    "        with tf.GradientTape() as tape:\n",
    "            p, v = self.model(s)\n",
    "            adv = r - v[0]\n",
    "            log_p = tf.math.log(p)\n",
    "\n",
    "            actor_loss = -tf.math.reduce_sum(log_p * adv)\n",
    "\n",
    "            critic_loss = self.huber_loss(v, r)\n",
    "\n",
    "            loss = actor_loss + critic_loss\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optim.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\dlkan\\AppData\\Local\\Temp\\ipykernel_12896\\1249415675.py\", line 40, in learn  *\n        print(tf.matmul(log_p, adv))\n\n    ValueError: Dimensions must be equal, but are 42 and 6889 for '{{node MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Log, sub)' with input shapes: [6889,42], [6889,6889].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m reward_history\u001b[38;5;241m.\u001b[39mappend(reward)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m---> 52\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     rewards \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;28;01mif\u001b[39;00m steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m EPISODE_DONE \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     55\u001b[0m     reward_hist[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(rewards)\n",
      "Cell \u001b[1;32mIn[18], line 30\u001b[0m, in \u001b[0;36mAC_agent.run\u001b[1;34m(self, state, rewards, steps)\u001b[0m\n\u001b[0;32m     27\u001b[0m states \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(state)\u001b[38;5;241m.\u001b[39mreshape(steps\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m21\u001b[39m)\n\u001b[0;32m     28\u001b[0m returns \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(returns)\n\u001b[1;32m---> 30\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filemvckphcx.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__learn\u001b[1;34m(self, s, r)\u001b[0m\n\u001b[0;32m     12\u001b[0m adv \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(r) \u001b[39m-\u001b[39m ag__\u001b[39m.\u001b[39mld(v)\n\u001b[0;32m     13\u001b[0m log_p \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mlog, (ag__\u001b[39m.\u001b[39mld(p),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 14\u001b[0m ag__\u001b[39m.\u001b[39mld(\u001b[39mprint\u001b[39m)(ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mmatmul, (ag__\u001b[39m.\u001b[39;49mld(log_p), ag__\u001b[39m.\u001b[39;49mld(adv)), \u001b[39mNone\u001b[39;49;00m, fscope))\n\u001b[0;32m     15\u001b[0m actor_loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mreduce_sum, (ag__\u001b[39m.\u001b[39mld(log_p) \u001b[39m*\u001b[39m ag__\u001b[39m.\u001b[39mld(adv),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m critic_loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mhuber_loss, (ag__\u001b[39m.\u001b[39mld(v), ag__\u001b[39m.\u001b[39mld(r)), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\dlkan\\AppData\\Local\\Temp\\ipykernel_12896\\1249415675.py\", line 40, in learn  *\n        print(tf.matmul(log_p, adv))\n\n    ValueError: Dimensions must be equal, but are 42 and 6889 for '{{node MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Log, sub)' with input shapes: [6889,42], [6889,6889].\n"
     ]
    }
   ],
   "source": [
    "agent = AC_agent()\n",
    "state_hist = []\n",
    "reward_hist = [[] for i in range(4)]\n",
    "loss_hist = []\n",
    "steps_list = []\n",
    "\n",
    "for e in range(10000):\n",
    "    counter = [0 for i in range(42)]\n",
    "    state = start\n",
    "    steps = 1\n",
    "    reward = return_reward(state, goal)\n",
    "\n",
    "    done = 0\n",
    "    rewards = 0\n",
    "    min_reward = 100\n",
    "    max_reward = -100\n",
    "\n",
    "    state_history = []\n",
    "    reward_history = []\n",
    "\n",
    "    while True:\n",
    "        # model_state = np.array([state, goal]).reshape(1, 42)\n",
    "        model_state = state\n",
    "        a_i, a_p, c_v = agent.act(model_state)\n",
    "        action = return_action(a_i)\n",
    "        counter[a_i] += 1\n",
    "\n",
    "        next_state = return_state(state, action)\n",
    "        reward = return_reward(next_state, goal)\n",
    "        # print(f'steps: {steps}, reward: {reward}, loss: {loss}')\n",
    "\n",
    "        state = next_state\n",
    "        rewards += reward\n",
    "        steps += 1\n",
    "\n",
    "        if steps == EPISODE_DONE or all(state[0] == goal[0]):\n",
    "            done = 1\n",
    "\n",
    "        if reward < min_reward:\n",
    "            min_reward = reward\n",
    "\n",
    "        if reward > max_reward:\n",
    "            max_reward = reward\n",
    "\n",
    "        steps_list.append(reward)\n",
    "        state_hist.append(state)\n",
    "\n",
    "        state_history.append(model_state)\n",
    "        reward_history.append(reward)\n",
    "\n",
    "        if done:\n",
    "            loss = agent.run(state_history, reward_history, steps)\n",
    "\n",
    "            rewards = rewards if steps - 1 == EPISODE_DONE else 0\n",
    "            reward_hist[0].append(rewards)\n",
    "            reward_hist[1].append(rewards/steps)\n",
    "            reward_hist[2].append(max_reward)\n",
    "            reward_hist[3].append(min_reward)\n",
    "            loss_hist.append(loss)\n",
    "            steps_list.append(0 if steps == EPISODE_DONE else 1)\n",
    "\n",
    "            print(f'{e if steps -1 == EPISODE_DONE else 0}: {round(min_reward, 1)}, {round(max_reward, 1)}, {round(reward, 1)}')\n",
    "            print(f\"mean rewards: {round(rewards/steps, 3)}, net_loss: {round(loss, 3)}, most action: {argmax(counter)}|{max(counter)}/{steps}\")\n",
    "            print(state[0])\n",
    "\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.51 0.5  0.5  0.49 0.5  0.5  0.5  0.5  0.5  0.5  0.49 0.5  0.5  0.5\n",
    "#  0.5  0.5  0.49 0.49 0.51 0.5  0.5 ]\n",
    "# [0.   0.98 0.   1.   0.99 1.   0.   0.78 0.09 0.46 0.4  0.58 0.27 0.32\n",
    "#  0.23 0.23 1.   0.03 0.5  0.43 1.  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(reward_hist[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: 79.1, i: 48\n",
      "r: 79.1, i: 54\n",
      "r: 79.1, i: 167\n",
      "r: 79.1, i: 179\n",
      "r: 79.1, i: 188\n",
      "r: 79.2, i: 196\n",
      "r: 79.1, i: 209\n",
      "r: 79.1, i: 210\n",
      "r: 79.1, i: 227\n",
      "r: 79.1, i: 258\n",
      "r: 79.1, i: 293\n",
      "r: 79.1, i: 342\n",
      "r: 79.1, i: 357\n",
      "r: 79.1, i: 388\n",
      "r: 79.1, i: 466\n",
      "r: 79.1, i: 563\n",
      "r: 79.1, i: 638\n",
      "r: 79.1, i: 676\n",
      "r: 79.1, i: 823\n",
      "r: 79.1, i: 854\n",
      "r: 79.1, i: 906\n",
      "r: 79.1, i: 916\n",
      "r: 79.1, i: 995\n",
      "r: 79.1, i: 1025\n",
      "r: 79.1, i: 1031\n",
      "r: 79.1, i: 1035\n",
      "r: 79.1, i: 1104\n",
      "r: 79.1, i: 1130\n",
      "r: 79.1, i: 1184\n",
      "r: 79.1, i: 1186\n",
      "r: 79.1, i: 1188\n",
      "r: 79.1, i: 1192\n",
      "r: 79.1, i: 1238\n",
      "r: 79.1, i: 1271\n",
      "r: 79.1, i: 1305\n",
      "r: 79.1, i: 1323\n",
      "r: 79.1, i: 1453\n",
      "r: 79.1, i: 1482\n",
      "r: 79.1, i: 1538\n",
      "r: 79.1, i: 1585\n",
      "r: 79.1, i: 1666\n",
      "r: 79.1, i: 1703\n",
      "r: 79.1, i: 1710\n",
      "r: 79.1, i: 1743\n",
      "r: 79.1, i: 1807\n",
      "r: 79.1, i: 1814\n",
      "r: 79.1, i: 1849\n",
      "r: 79.1, i: 1864\n",
      "r: 79.1, i: 1878\n",
      "r: 79.1, i: 1992\n",
      "r: 79.1, i: 2052\n",
      "r: 79.1, i: 2117\n",
      "r: 79.1, i: 2136\n",
      "r: 79.1, i: 2169\n",
      "r: 79.1, i: 2222\n",
      "r: 79.1, i: 2225\n",
      "r: 79.1, i: 2227\n",
      "r: 79.1, i: 2248\n",
      "r: 79.1, i: 2378\n",
      "r: 79.1, i: 2404\n",
      "r: 79.1, i: 2469\n",
      "r: 79.1, i: 2500\n",
      "r: 79.1, i: 2514\n",
      "r: 79.1, i: 2523\n",
      "r: 79.1, i: 2603\n",
      "r: 79.1, i: 2623\n",
      "r: 79.1, i: 2653\n",
      "r: 79.1, i: 2732\n",
      "r: 79.1, i: 2798\n",
      "r: 79.1, i: 2815\n",
      "r: 79.1, i: 2839\n",
      "r: 79.1, i: 2869\n",
      "r: 79.1, i: 2913\n",
      "r: 79.1, i: 2940\n",
      "r: 79.1, i: 2985\n",
      "r: 79.1, i: 3041\n",
      "r: 79.1, i: 3087\n",
      "r: 79.1, i: 3152\n",
      "r: 79.1, i: 3182\n",
      "r: 79.1, i: 3202\n",
      "r: 79.1, i: 3203\n",
      "r: 79.1, i: 3220\n",
      "r: 79.1, i: 3222\n",
      "r: 79.1, i: 3244\n",
      "r: 79.1, i: 3270\n",
      "r: 79.1, i: 3277\n",
      "r: 79.1, i: 3278\n",
      "r: 79.1, i: 3314\n",
      "r: 79.1, i: 3337\n",
      "r: 79.1, i: 3380\n",
      "r: 79.1, i: 3386\n",
      "r: 79.1, i: 3411\n",
      "r: 79.1, i: 3454\n",
      "r: 79.2, i: 3563\n",
      "r: 79.1, i: 3613\n",
      "r: 79.1, i: 3659\n",
      "r: 79.1, i: 3817\n",
      "r: 79.1, i: 3999\n",
      "r: 79.1, i: 4001\n",
      "r: 79.1, i: 4024\n",
      "r: 79.1, i: 4052\n",
      "r: 79.1, i: 4061\n",
      "r: 79.1, i: 4074\n",
      "r: 79.1, i: 4139\n",
      "r: 79.1, i: 4146\n",
      "r: 79.1, i: 4163\n",
      "r: 79.1, i: 4177\n",
      "r: 79.1, i: 4189\n",
      "r: 79.1, i: 4209\n",
      "r: 79.1, i: 4237\n",
      "r: 79.1, i: 4361\n",
      "r: 79.1, i: 4378\n",
      "r: 79.1, i: 4382\n",
      "r: 79.1, i: 4431\n",
      "r: 79.1, i: 4445\n",
      "r: 79.1, i: 4469\n",
      "r: 79.1, i: 4503\n",
      "r: 79.1, i: 4539\n",
      "r: 79.1, i: 4551\n",
      "r: 79.1, i: 4558\n",
      "r: 79.1, i: 4578\n",
      "r: 79.1, i: 4598\n",
      "r: 79.1, i: 4673\n",
      "r: 79.1, i: 4702\n",
      "r: 79.1, i: 4877\n",
      "r: 79.1, i: 4914\n",
      "r: 79.1, i: 4971\n",
      "r: 79.1, i: 5009\n",
      "r: 79.1, i: 5031\n",
      "r: 79.1, i: 5039\n",
      "r: 79.1, i: 5076\n",
      "r: 79.1, i: 5101\n",
      "r: 79.1, i: 5115\n",
      "r: 79.1, i: 5138\n",
      "r: 79.1, i: 5141\n",
      "r: 79.1, i: 5193\n",
      "r: 79.1, i: 5228\n",
      "r: 79.1, i: 5245\n",
      "r: 79.1, i: 5276\n",
      "r: 79.1, i: 5349\n",
      "r: 79.1, i: 5356\n",
      "r: 79.1, i: 5385\n",
      "r: 79.1, i: 5387\n",
      "r: 79.1, i: 5469\n",
      "r: 79.1, i: 5575\n",
      "r: 79.1, i: 5641\n",
      "r: 79.1, i: 5694\n",
      "r: 79.1, i: 5780\n",
      "r: 79.1, i: 5804\n",
      "r: 79.1, i: 5834\n",
      "r: 79.1, i: 5887\n",
      "r: 79.1, i: 5926\n",
      "r: 79.1, i: 5934\n",
      "r: 79.1, i: 6037\n",
      "r: 79.1, i: 6055\n",
      "r: 79.1, i: 6074\n",
      "r: 79.1, i: 6098\n",
      "r: 79.1, i: 6118\n",
      "r: 79.1, i: 6164\n",
      "r: 79.1, i: 6169\n",
      "r: 79.1, i: 6174\n",
      "r: 79.1, i: 6217\n",
      "r: 79.1, i: 6291\n",
      "r: 79.1, i: 6295\n",
      "r: 79.1, i: 6300\n",
      "r: 79.1, i: 6373\n",
      "r: 79.1, i: 6403\n",
      "r: 79.1, i: 6454\n",
      "r: 79.1, i: 6464\n",
      "r: 79.1, i: 6490\n",
      "r: 79.1, i: 6529\n",
      "r: 79.1, i: 6543\n",
      "r: 79.1, i: 6546\n",
      "r: 79.1, i: 6557\n",
      "r: 79.1, i: 6571\n",
      "r: 79.1, i: 6593\n",
      "r: 79.1, i: 6600\n",
      "r: 79.1, i: 6610\n",
      "r: 79.1, i: 6618\n",
      "r: 79.2, i: 6693\n",
      "r: 79.1, i: 6718\n",
      "r: 79.2, i: 6726\n",
      "r: 79.1, i: 6730\n",
      "r: 79.1, i: 6742\n",
      "r: 79.1, i: 6797\n",
      "r: 79.1, i: 6799\n",
      "r: 79.1, i: 6826\n",
      "r: 79.1, i: 6839\n",
      "r: 79.1, i: 6854\n",
      "r: 79.1, i: 6860\n",
      "r: 79.1, i: 6887\n",
      "r: 79.1, i: 6940\n",
      "r: 79.1, i: 6965\n",
      "r: 79.1, i: 7039\n",
      "r: 79.2, i: 7045\n",
      "r: 79.1, i: 7048\n",
      "r: 79.1, i: 7067\n",
      "r: 79.1, i: 7157\n",
      "r: 79.1, i: 7158\n",
      "r: 79.1, i: 7188\n",
      "r: 79.1, i: 7211\n",
      "r: 79.1, i: 7265\n",
      "r: 79.1, i: 7267\n",
      "r: 79.1, i: 7328\n",
      "r: 79.1, i: 7331\n",
      "r: 79.1, i: 7355\n",
      "r: 79.1, i: 7363\n",
      "r: 79.1, i: 7387\n",
      "r: 79.1, i: 7452\n",
      "r: 79.1, i: 7496\n",
      "r: 79.1, i: 7503\n",
      "r: 79.1, i: 7527\n",
      "r: 79.1, i: 7622\n",
      "r: 79.2, i: 7696\n",
      "r: 79.1, i: 7711\n",
      "r: 79.1, i: 7757\n",
      "r: 79.1, i: 7766\n",
      "r: 79.1, i: 7812\n",
      "r: 79.1, i: 7849\n",
      "r: 79.1, i: 7859\n",
      "r: 79.1, i: 7888\n",
      "r: 79.1, i: 7911\n",
      "r: 79.1, i: 7913\n",
      "r: 79.1, i: 7922\n",
      "r: 79.1, i: 7941\n",
      "r: 79.1, i: 7967\n",
      "r: 79.1, i: 7968\n",
      "r: 79.1, i: 8003\n",
      "r: 79.1, i: 8007\n",
      "r: 79.1, i: 8034\n",
      "r: 79.1, i: 8056\n",
      "r: 79.1, i: 8082\n",
      "r: 79.1, i: 8128\n",
      "r: 79.1, i: 8165\n",
      "r: 79.1, i: 8221\n",
      "r: 79.1, i: 8236\n",
      "r: 79.1, i: 8250\n",
      "r: 79.1, i: 8291\n",
      "r: 79.1, i: 8294\n",
      "r: 79.1, i: 8333\n",
      "r: 79.1, i: 8370\n",
      "r: 79.1, i: 8399\n",
      "r: 79.1, i: 8475\n",
      "r: 79.1, i: 8494\n",
      "r: 79.1, i: 8564\n",
      "r: 79.1, i: 8612\n",
      "r: 79.1, i: 8689\n",
      "r: 79.1, i: 8730\n",
      "r: 79.1, i: 8734\n",
      "r: 79.1, i: 8741\n",
      "r: 79.1, i: 8779\n",
      "r: 79.1, i: 8897\n",
      "r: 79.1, i: 8913\n",
      "r: 79.1, i: 8922\n",
      "r: 79.1, i: 8926\n",
      "r: 79.1, i: 8972\n",
      "r: 79.1, i: 9015\n",
      "r: 79.1, i: 9081\n",
      "r: 79.1, i: 9095\n",
      "r: 79.1, i: 9099\n",
      "r: 79.1, i: 9113\n",
      "r: 79.1, i: 9127\n",
      "r: 79.1, i: 9151\n",
      "r: 79.1, i: 9209\n",
      "r: 79.1, i: 9220\n",
      "r: 79.1, i: 9232\n",
      "r: 79.1, i: 9255\n",
      "r: 79.1, i: 9287\n",
      "r: 79.1, i: 9308\n",
      "r: 79.1, i: 9407\n",
      "r: 79.1, i: 9552\n",
      "r: 79.1, i: 9562\n",
      "r: 79.1, i: 9665\n",
      "r: 79.1, i: 9695\n",
      "r: 79.1, i: 9713\n",
      "r: 79.1, i: 9737\n",
      "r: 79.1, i: 9761\n",
      "r: 79.1, i: 9919\n",
      "r: 79.1, i: 9962\n",
      "r: 79.1, i: 9978\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(reward_hist[2]):\n",
    "    if r > 79:\n",
    "        print(f'r: {r}, i: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78ddfc3686b8b7161f2836984651df038ec9a0366954334fc42499f59ad2b3c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
